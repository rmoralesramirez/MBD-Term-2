{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flights Analysis (January 2008)\n",
    "\n",
    "Flights analysis is going to be performed as follows:\n",
    "\n",
    "1. PySpark **environment setup**\n",
    "2. Data source and **Spark data abstraction** (DataFrame) **set up**\n",
    "3. Data set **metadata analysis**:\n",
    "  1. Display **schema and size** of the DataFrame\n",
    "  2. Get one or multiple **random samples** from the data set to better understand what the data is all about\n",
    "  3. Identify **data entities**, **metrics** and **dimensions**\n",
    "  4. **Columns/fields categorization**\n",
    "4. Columns groups **basic profiling** to better understand our data set:\n",
    "  1. **Timing related** columns basic profiling\n",
    "  2. **Flight related** columns basic profiling\n",
    "  3. **Issue related** columns basic profiling\n",
    "5. **Answer some business questions** to improve service\n",
    "  1. **Ratio of delayed** (and no cancelled) flights by severity\n",
    "  2. **Severe delayed flights statistics** by type of delay (carrier, weather, NAS, security and lateaircraft)\n",
    "  3. **Top 20 origin airports** (and figures) involved in severe delays\n",
    "\n",
    "Let's go for it:\n",
    "\n",
    "## 1. PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data source and Spark data abstraction (DataFrame) setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDF = spark.read \\\n",
    "                 .option(\"inferSchema\", \"true\") \\\n",
    "                 .option(\"header\", \"true\") \\\n",
    "                 .csv(\"flights_jan08.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data set metadata analysis\n",
    "### A. Display schema and size of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "flightsDF.printSchema()\n",
    "display(Markdown(\"This DataFrame has **%d rows**.\" % flightsDF.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Get one or multiple random samples from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDF.cache() # optimization to make the processing faster\n",
    "flightsDF.sample(False, 0.1).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data entities, metrics and dimensions\n",
    "\n",
    "I've identified the following elements:\n",
    "\n",
    "* **Entities:** Flight (main one which is measured - facts), Airport (dimension), Air Carrier (dimension)\n",
    "* **Metrics:** Departure time, scheduled departure time, arrival time, scheduled arrival time, ...\n",
    "* **Dimensions:** Origin, destination, tailNum, flight number, ...\n",
    "\n",
    "### D. Column categorization\n",
    "\n",
    "The following could be a potential column categorization:\n",
    "\n",
    "* **Timing related columns:** *Year*, *Month*, *DayofMonth*, *DayOfWeek*, *DepTime*, *CRSDepTime*, *ArrTime* and *CRSArrTime*\n",
    "* **Flight related columns:** *UniqueCarrier*, *FlightNum*, *TailNum*, *ActualElapsedTime*, *CRSElapsedTime*, *AirTime*, *Origin*, *Dest*, *Distance*, *TaxiIn* and *TaxiOut*\n",
    "* **Issue related columns:** *ArrDelay*, *DepDelay*, *Cancelled*, *CancellationCode*, *Diverted*, *CarrierDelay*, *WeatherDelay*, *NASDelay*, *SecurityDelay* and *LateAircraftDelay*\n",
    "\n",
    "## 4. Columns groups basic profiling to better understand our data set\n",
    "### A. Timing related columns basic profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "\n",
    "\n",
    "print (\"Summary of columns Year, Month, DayofMonth and DayOfWeek:\")\n",
    "flightsDF.select(\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns Year, Month, DayofMonth and DayOfWeek:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns Year, Month, DayofMonth and DayOfWeek:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\"]]).show()\n",
    "\n",
    "print (\"Most and least frequent occurrences for DayofMonth and DayOfWeek columns:\")\n",
    "dayofMonthOccurrencesDF = flightsDF.groupBy(\"DayofMonth\").agg(count(lit(1)).alias(\"Total\"))\n",
    "dayOfWeekDF = flightsDF.groupBy(\"DayOfWeek\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "leastFreqDayOfMonth    = dayofMonthOccurrencesDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqDayOfMonth     = dayofMonthOccurrencesDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqDayOfWeek     = dayOfWeekDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqDayOfWeek      = dayOfWeekDF.orderBy(col(\"Total\").desc()).first()\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqDayOfMonth\", \"mostFreqDayOfMonth\", \"leastFreqDayOfWeek\", \"mostFreqDayOfWeek\", \\\n",
    "       \"%d (%d occurrences)\" % (leastFreqDayOfMonth[\"DayofMonth\"], leastFreqDayOfMonth[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (mostFreqDayOfMonth[\"DayofMonth\"], mostFreqDayOfMonth[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (leastFreqDayOfWeek[\"DayOfWeek\"], leastFreqDayOfWeek[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (mostFreqDayOfWeek[\"DayOfWeek\"], mostFreqDayOfWeek[\"Total\"]))))\n",
    "\n",
    "print (\"Summary of columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\")\n",
    "flightsDF.select(\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\"]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Flight related columns basic profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first\n",
    "\n",
    "print (\"Summary of columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\")\n",
    "flightsDF.select(\"UniqueCarrier\", \"FlightNum\", \"TailNum\", \"Origin\", \"Dest\", \"Distance\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"UniqueCarrier\", \"FlightNum\", \"TailNum\", \"Origin\", \"Dest\", \"Distance\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"UniqueCarrier\", \"FlightNum\", \"TailNum\", \"Origin\", \"Dest\", \"Distance\"]]).show()\n",
    "\n",
    "print (\"Most and least frequent occurrences for FlightNum, TailNum, Origin and Dest columns:\")\n",
    "FlightNumDF = flightsDF.groupBy(\"FlightNum\").agg(count(lit(1)).alias(\"Total\"))\n",
    "TailNumDF   = flightsDF.groupBy(\"TailNum\").agg(count(lit(1)).alias(\"Total\"))\n",
    "OriginDF    = flightsDF.groupBy(\"Origin\").agg(count(lit(1)).alias(\"Total\"))\n",
    "DestDF      = flightsDF.groupBy(\"Dest\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "leastFreqFlightNum    = FlightNumDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqFlightNum     = FlightNumDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqTailNum      = TailNumDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqTailNum       = TailNumDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqOrigin       = OriginDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqOrigin        = OriginDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqDest         = DestDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqDest          = DestDF.orderBy(col(\"Total\").desc()).first()\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqFlightNum\", \"mostFreqFlightNum\", \"leastFreqTailNum\", \"mostFreqTailNum\", \\\n",
    "       \"%d (%d occurrences)\" % (leastFreqFlightNum[\"FlightNum\"], leastFreqFlightNum[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (mostFreqFlightNum[\"FlightNum\"], mostFreqFlightNum[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqTailNum[\"TailNum\"], leastFreqTailNum[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqTailNum[\"TailNum\"], mostFreqTailNum[\"Total\"]))))\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqOrigin\", \"mostFreqOrigin\", \"leastFreqDest\", \"mostFreqDest\", \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqOrigin[\"Origin\"], leastFreqOrigin[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqOrigin[\"Origin\"], mostFreqOrigin[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqDest[\"Dest\"], leastFreqDest[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqDest[\"Dest\"], mostFreqDest[\"Total\"]))))\n",
    "\n",
    "print (\"Summary of columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\")\n",
    "flightsDF.select(\"ActualElapsedTime\", \"CRSElapsedTime\", \"AirTime\", \"TaxiIn\", \"TaxiOut\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"ActualElapsedTime\", \"CRSElapsedTime\", \"AirTime\", \"TaxiIn\", \"TaxiOut\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"ActualElapsedTime\", \"CRSElapsedTime\", \"AirTime\", \"TaxiIn\", \"TaxiOut\"]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Issue related columns basic profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first\n",
    "\n",
    "print (\"Summary of columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\")\n",
    "flightsDF.select(\"ArrDelay\", \"DepDelay\", \"Cancelled\", \"CancellationCode\", \"Diverted\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"ArrDelay\", \"DepDelay\", \"Cancelled\", \"CancellationCode\", \"Diverted\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"ArrDelay\", \"DepDelay\", \"Cancelled\", \"CancellationCode\", \"Diverted\"]]).show()\n",
    "\n",
    "print (\"Summary of columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\")\n",
    "flightsDF.select(\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"]]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Answer some business questions to improve service\n",
    "\n",
    "### A. Ratio of delayed (and no cancelled) flights by severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, round\n",
    "\n",
    "# Delay severity is going to be categorized as follows (totally made up):\n",
    "#\n",
    "#   \"nodelay\"      - delay=(-infinity,0] mins\n",
    "#   \"acceptable\"   - delay=(0,15] mins\n",
    "#   \"annoying\"     - delay=(15,30] mins\n",
    "#   \"impactul\"     - delay=(30,60] mins\n",
    "#   \"unacceptable\" - delay=(60,+infinity) mins\n",
    "\n",
    "# 1. Let's enrich the DF with delay severity based on our categorization\n",
    "totalFlights = flightsDF.count()\n",
    "delayCategorizationDF = flightsDF\\\n",
    "   .where(col(\"ArrDelay\")!=\"NA\")\\\n",
    "   .withColumn(\"DelaySeverity\", when(col(\"ArrDelay\")<=0,\"1.nodelay\")\\\n",
    "                               .when((col(\"ArrDelay\")>0) & (col(\"ArrDelay\")<=15),\"2.acceptable\")\\\n",
    "                               .when((col(\"ArrDelay\")>15) & (col(\"ArrDelay\")<=30),\"3.annoying\")\\\n",
    "                               .when((col(\"ArrDelay\")>30) & (col(\"ArrDelay\")<=60),\"4.impactul\")\\\n",
    "                               .otherwise(\"5.unacceptable\"))\n",
    "delayCategorizationDF.cache() # optimization to make the processing faster\n",
    "# 2. Ready to answer to this business question\n",
    "delayCategorizationDF.where(col(\"Cancelled\")==0)\\\n",
    "                     .select(\"DelaySeverity\", \"ArrDelay\")\\\n",
    "                     .groupBy(\"DelaySeverity\")\\\n",
    "                     .agg(count(\"DelaySeverity\").alias(\"NumFlights\"), \\\n",
    "                          (count(\"DelaySeverity\")/totalFlights*100).alias(\"Ratio\"))\\\n",
    "                     .orderBy(\"DelaySeverity\")\\\n",
    "                     .select(\"DelaySeverity\",\"NumFlights\",round(\"Ratio\",2).alias(\"RoundedRatio\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Severe delayed flights statistics by type of delay (carrier, weather, NAS, security and lateaircraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, min, avg, stddev\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# To get statistics of severe delayed flights, we have to prepare the previous DataFrame (delayCategorizationDF):\n",
    "#   1. Remove cancelled flights\n",
    "#   2. Keep only severe delayed flights: annoying, impactful and unacceptable\n",
    "#   3. To get proper statistics, convert String columns with delay info into Integer columns\n",
    "#      (none of the converted fields contain \"NA\" as value in severeDelaysDF - you can easily check this out) \n",
    "#\n",
    "severeDelaysDF = \\\n",
    "  delayCategorizationDF.where((col(\"Cancelled\")==0))\\\n",
    "                       .where((col(\"DelaySeverity\")!=\"1.nodelay\") & (col(\"DelaySeverity\")!=\"2.acceptable\"))\\\n",
    "                       .withColumn(\"IntArrDelay\", col(\"ArrDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntCarrierDelay\", col(\"CarrierDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntWeatherDelay\", col(\"WeatherDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntNASDelay\", col(\"NASDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntSecurityDelay\", col(\"SecurityDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntLateAircraftDelay\", col(\"LateAircraftDelay\").cast(IntegerType()))\\\n",
    "                       .select(\"DelaySeverity\", \"IntArrDelay\",\"IntCarrierDelay\",\"IntWeatherDelay\",\\\n",
    "                               \"IntNASDelay\", \"IntSecurityDelay\", \"IntLateAircraftDelay\")\n",
    "severeDelaysDF.cache() # optimization to make the processing faster\n",
    "\n",
    "display(Markdown(\"**'Arrival' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntArrDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntArrDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntArrDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntArrDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'Carrier' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntCarrierDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntCarrierDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntCarrierDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntCarrierDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'Weather' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntWeatherDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntWeatherDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntWeatherDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntWeatherDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'NAS' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntNASDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntNASDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntNASDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntNASDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'Security' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntSecurityDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntSecurityDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntSecurityDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntSecurityDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'LateAircraft' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntLateAircraftDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntLateAircraftDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntLateAircraftDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntLateAircraftDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Top 20 origin airports (and figures) involved in severe delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our answer to this business question will be:\n",
    "#   1. List of top 20 origin airports with highest severe delayed (aka unacceptable) flights ratio \n",
    "#      (based on total number of flights)\n",
    "#   2. List of top 20 origin airports with severe delayed flights ratio by severity category (unacceptable,\n",
    "#      impactful and annoying)\n",
    "\n",
    "# In order to be able to deliver these insights, we need some preparation:\n",
    "#   1. Define a DataFrame with total flights per Origin airport (totalFlightsOriginDF)\n",
    "#   2. Define a DataFrame with aggregated data by Origin and DelaySeverity to figure out\n",
    "#      number of flights delayed per severity category (severeDelaysOriginDF)\n",
    "#   3. Combine both DataFrames to come up with one single DataFrame containin total flights\n",
    "#      per origin airport and number of flights delayed by severity to compute ratios (combinedDF)\n",
    "\n",
    "totalFlightsOriginDF = \\\n",
    "   flightsDF.groupBy(\"Origin\")\\\n",
    "            .agg(count(\"ArrDelay\").alias(\"TotalFlights\"))\n",
    "severeDelaysOriginDF = \\\n",
    "  delayCategorizationDF.where((col(\"Cancelled\")==0))\\\n",
    "                       .where((col(\"DelaySeverity\")!=\"1.nodelay\") & (col(\"DelaySeverity\")!=\"2.acceptable\"))\\\n",
    "                       .withColumn(\"IntArrDelay\", col(\"ArrDelay\").cast(IntegerType()))\\\n",
    "                       .select(\"DelaySeverity\", \"IntArrDelay\",\"Origin\")\\\n",
    "                       .groupBy(\"Origin\", \"DelaySeverity\")\\\n",
    "                       .agg(count(\"IntArrDelay\").alias(\"NumSevereDelayedFlights\"))\n",
    "combinedDF = \\\n",
    "  severeDelaysOriginDF\\\n",
    "     .join(totalFlightsOriginDF, \"Origin\")\\\n",
    "     .withColumn(\"SevereDelayedRatio\", round(col(\"NumSevereDelayedFlights\")/col(\"TotalFlights\")*100,2))\\\n",
    "     .orderBy(col(\"SevereDelayedRatio\").desc())\n",
    "combinedDF.cache() # optimization to make the processing faster\n",
    "\n",
    "display(Markdown(\"**Top 20 origin airports** with highest severe delayed (**unacceptable**) flights ratio (in \\%):\"))\n",
    "combinedDF.limit(20).show()\n",
    "display(Markdown(\"**Top 20 origin airports with severe delayed flights ratio** by severity category (in \\%):\"))\n",
    "combinedDF\\\n",
    "   .groupBy(\"Origin\")\\\n",
    "   .pivot(\"DelaySeverity\")\\\n",
    "   .min(\"SevereDelayedRatio\")\\\n",
    "   .orderBy(col(\"`5.unacceptable`\").desc(), col(\"`4.impactul`\").desc(), col(\"`3.annoying`\").desc())\\\n",
    "   .limit(20).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
